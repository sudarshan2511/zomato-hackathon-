{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3 — Candidate Generation\n",
        "\n",
        "**CSAO Rail Recommendation System · Zomathon Hackathon**\n",
        "\n",
        "Pre-computed item embeddings (Sentence Transformers `all-MiniLM-L6-v2`) + exact dot product search via numpy.\n",
        "\n",
        "| Component | Detail |\n",
        "|-----------|--------|\n",
        "| **Offline** | Encode every menu item once, save embeddings to disk |\n",
        "| **Runtime** | Mean-pool cart embeddings into query vector, dot product against filtered candidates, take top 50 |\n",
        "| **Scale** | 30–80 candidates after hard filters — exact search faster than FAISS at this size |"
      ],
      "id": "c5ea3cd8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath(\"..\"))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from hard_filters import HardFilterPipeline\n",
        "from candidate_generation import CandidateGenerator, generate_and_save_embeddings\n",
        "\n",
        "DATA = \"../data\"\n",
        "EMBEDDINGS_PATH = f\"{DATA}/item_embeddings.npz\"\n",
        "\n",
        "restaurants = pd.read_csv(f\"{DATA}/restaurants.csv\")\n",
        "menu        = pd.read_csv(f\"{DATA}/menu_items.csv\")\n",
        "users       = pd.read_csv(f\"{DATA}/users.csv\")\n",
        "sessions    = pd.read_csv(f\"{DATA}/sessions.csv\")\n",
        "events      = pd.read_csv(f\"{DATA}/cart_events.csv\")\n",
        "\n",
        "pipe = HardFilterPipeline(menu, restaurants, users)\n",
        "cgen = CandidateGenerator(EMBEDDINGS_PATH)\n",
        "\n",
        "print(f\"Menu items   : {len(menu):>6,}\")\n",
        "print(f\"Sessions     : {len(sessions):>6,}\")\n",
        "print(f\"Embeddings   : {cgen.n_items:>6,} items x {cgen.dim} dims\")\n",
        "print(\"Pipeline loaded.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f437b83e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pre-compute cart items per session (fast groupby instead of per-row filtering)\n",
        "_cart_events = events[events[\"cart_position\"].notna()]\n",
        "_cart_by_session = _cart_events.groupby(\"session_id\")[\"item_id\"].apply(set).to_dict()\n",
        "\n",
        "def get_cart_items(session_id):\n",
        "    \"\"\"Return the set of item_ids in a session's cart.\"\"\"\n",
        "    return _cart_by_session.get(session_id, set())\n",
        "\n",
        "def get_cart_df(cart_ids):\n",
        "    \"\"\"Return menu rows for items in the cart.\"\"\"\n",
        "    return menu[menu[\"item_id\"].isin(cart_ids)]\n",
        "\n",
        "_rest_cuisine = dict(zip(restaurants[\"restaurant_id\"], restaurants[\"primary_cuisine\"]))\n",
        "\n",
        "def get_restaurant_cuisine(restaurant_id):\n",
        "    \"\"\"Look up a restaurant's primary cuisine.\"\"\"\n",
        "    return _rest_cuisine.get(restaurant_id)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b4cc34cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Embedding Inspection\n",
        "\n",
        "Verify the pre-computed embeddings: shape, normalization, and basic statistics."
      ],
      "id": "6a7c21e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = np.load(EMBEDDINGS_PATH, allow_pickle=True)\n",
        "embeddings = data[\"embeddings\"]\n",
        "item_ids = data[\"item_ids\"]\n",
        "\n",
        "norms = np.linalg.norm(embeddings, axis=1)\n",
        "\n",
        "print(\"=== Embedding Summary ===\")\n",
        "print(f\"  Shape          : {embeddings.shape}\")\n",
        "print(f\"  Dtype          : {embeddings.dtype}\")\n",
        "print(f\"  L2 norm range  : [{norms.min():.6f}, {norms.max():.6f}]\")\n",
        "print(f\"  L2 norm mean   : {norms.mean():.6f}\")\n",
        "print(f\"  File size      : {os.path.getsize(EMBEDDINGS_PATH) / 1024:.0f} KB\")\n",
        "print()\n",
        "\n",
        "mean_vec = embeddings.mean(axis=0)\n",
        "print(f\"  Mean vector norm : {np.linalg.norm(mean_vec):.4f}\")\n",
        "print(f\"  Variance per dim : {embeddings.var(axis=0).mean():.6f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e4c94d40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Embedding Space Visualization\n",
        "\n",
        "PCA and t-SNE projections of all item embeddings, colored by cuisine and category."
      ],
      "id": "8f05852d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map item_ids back to menu metadata for coloring\n",
        "id_to_idx = {iid: i for i, iid in enumerate(item_ids)}\n",
        "emb_cuisine = menu[\"item_id\"].map(lambda x: menu.loc[menu[\"item_id\"] == x, \"cuisine_tag\"].values[0] if x in id_to_idx else None)\n",
        "\n",
        "# Faster lookup\n",
        "cuisine_map = dict(zip(menu[\"item_id\"], menu[\"cuisine_tag\"]))\n",
        "category_map = dict(zip(menu[\"item_id\"], menu[\"category\"]))\n",
        "cuisines = np.array([cuisine_map.get(iid, \"Unknown\") for iid in item_ids])\n",
        "categories = np.array([category_map.get(iid, \"Unknown\") for iid in item_ids])\n",
        "\n",
        "# PCA (fast, for structure overview)\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "emb_2d_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# By cuisine\n",
        "ax = axes[0]\n",
        "unique_cuisines = sorted(set(cuisines))\n",
        "for cuisine in unique_cuisines:\n",
        "    mask = cuisines == cuisine\n",
        "    ax.scatter(emb_2d_pca[mask, 0], emb_2d_pca[mask, 1], s=8, alpha=0.6, label=cuisine)\n",
        "ax.set_title(\"PCA - Colored by Cuisine\")\n",
        "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%})\")\n",
        "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%})\")\n",
        "ax.legend(fontsize=7, markerscale=2, loc=\"best\")\n",
        "\n",
        "# By category\n",
        "ax2 = axes[1]\n",
        "unique_cats = sorted(set(categories))\n",
        "for cat in unique_cats:\n",
        "    mask = categories == cat\n",
        "    ax2.scatter(emb_2d_pca[mask, 0], emb_2d_pca[mask, 1], s=8, alpha=0.6, label=cat)\n",
        "ax2.set_title(\"PCA - Colored by Category\")\n",
        "ax2.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%})\")\n",
        "ax2.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%})\")\n",
        "ax2.legend(fontsize=7, markerscale=2, loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9a74f751"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# t-SNE (higher quality non-linear projection, slower)\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
        "emb_2d_tsne = tsne.fit_transform(embeddings)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax = axes[0]\n",
        "for cuisine in unique_cuisines:\n",
        "    mask = cuisines == cuisine\n",
        "    ax.scatter(emb_2d_tsne[mask, 0], emb_2d_tsne[mask, 1], s=8, alpha=0.6, label=cuisine)\n",
        "ax.set_title(\"t-SNE - Colored by Cuisine\")\n",
        "ax.legend(fontsize=7, markerscale=2, loc=\"best\")\n",
        "\n",
        "ax2 = axes[1]\n",
        "for cat in unique_cats:\n",
        "    mask = categories == cat\n",
        "    ax2.scatter(emb_2d_tsne[mask, 0], emb_2d_tsne[mask, 1], s=8, alpha=0.6, label=cat)\n",
        "ax2.set_title(\"t-SNE - Colored by Category\")\n",
        "ax2.legend(fontsize=7, markerscale=2, loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "928dcde0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Single Session Walkthrough\n",
        "\n",
        "Full pipeline: Step 2 hard filters -> Step 3 candidate generation -> ranked top 50."
      ],
      "id": "3dd5b1a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pick a session with a reasonable cart size (2-4 items)\n",
        "_session_cart_sizes = {sid: len(ids) for sid, ids in _cart_by_session.items()}\n",
        "sessions[\"cart_size\"] = sessions[\"session_id\"].map(_session_cart_sizes).fillna(0).astype(int)\n",
        "good_sessions = sessions[(sessions[\"cart_size\"] >= 2) & (sessions[\"cart_size\"] <= 4)]\n",
        "sample_session = good_sessions.iloc[0]\n",
        "\n",
        "sid = sample_session[\"session_id\"]\n",
        "rid = sample_session[\"restaurant_id\"]\n",
        "uid = sample_session[\"user_id\"]\n",
        "cuisine = get_restaurant_cuisine(rid)\n",
        "\n",
        "cart_ids = get_cart_items(sid)\n",
        "cart_df = get_cart_df(cart_ids)\n",
        "\n",
        "print(f\"=== Session {sid} ===\")\n",
        "print(f\"  Restaurant : {rid} ({cuisine})\")\n",
        "print(f\"  User       : {uid} (segment: {users[users['user_id']==uid].iloc[0]['segment']})\")\n",
        "print(f\"  Toggle     : {sample_session['dietary_toggle']}\")\n",
        "print(f\"  Cart ({len(cart_ids)} items):\")\n",
        "for _, item in cart_df.iterrows():\n",
        "    veg = \"V\" if item[\"veg_flag\"] else \"NV\"\n",
        "    print(f\"    {item['item_id']}  {item['name']:<35} Rs {item['price']:>4}  [{veg}] {item['category']}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7ad80fb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 2: Hard filters\n",
        "filtered_df, flog = pipe.run_filters(\n",
        "    restaurant_id=rid,\n",
        "    user_id=uid,\n",
        "    session_start=sample_session[\"start_time\"],\n",
        "    dietary_toggle=sample_session[\"dietary_toggle\"],\n",
        "    cart_item_ids=cart_ids,\n",
        ")\n",
        "\n",
        "print(f\"=== Hard Filter Funnel ===\")\n",
        "print(f\"  Initial menu   : {flog['initial']}\")\n",
        "print(f\"  After Filter A : {flog['after_A']}  (availability & margin)\")\n",
        "print(f\"  After Filter B : {flog['after_B']}  (dietary)\")\n",
        "print(f\"  After Filter C : {flog['after_C']}  (cuisine coherence)\")\n",
        "print(f\"  After Filter D : {flog['after_D']}  (quantity saturation)\")\n",
        "print(f\"  After Filter E : {flog['after_E']}  (dedup & fatigue)\")\n",
        "print(f\"\\n  Candidates for Step 3: {len(filtered_df)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "11d27492"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 3: Candidate generation\n",
        "top_candidates = cgen.generate_candidates(\n",
        "    cart_item_ids=cart_ids,\n",
        "    filtered_candidates_df=filtered_df,\n",
        "    restaurant_cuisine=cuisine,\n",
        "    top_k=50,\n",
        ")\n",
        "\n",
        "print(f\"=== Top Candidates (showing top 15 of {len(top_candidates)}) ===\")\n",
        "print(f\"{'Rank':<5} {'Score':<7} {'Item':<35} {'Cat':<12} {'Subcat':<15} {'Price':>6} {'VF':<3}\")\n",
        "print(\"-\" * 90)\n",
        "for rank, (_, row) in enumerate(top_candidates.head(15).iterrows(), 1):\n",
        "    vf = \"V\" if row[\"veg_flag\"] else \"NV\"\n",
        "    print(f\"{rank:<5} {row['similarity_score']:.4f}  {row['name']:<35} {row['category']:<12} {row['subcategory']:<15} Rs {row['price']:>4}  {vf}\")\n",
        "\n",
        "print(f\"\\n  Score range: [{top_candidates['similarity_score'].min():.4f}, {top_candidates['similarity_score'].max():.4f}]\")\n",
        "print(f\"  Categories in top 50: {dict(top_candidates['category'].value_counts())}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "46a688f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Edge Cases\n",
        "\n",
        "### 4a. Empty Cart (Cold Start)\n",
        "No items in cart — query vector falls back to restaurant cuisine name."
      ],
      "id": "53da7c09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Empty cart — cold start fallback\n",
        "cold_rest = restaurants[restaurants[\"primary_cuisine\"] == \"Chinese\"].iloc[0]\n",
        "cold_rid = cold_rest[\"restaurant_id\"]\n",
        "cold_cuisine = cold_rest[\"primary_cuisine\"]\n",
        "\n",
        "cold_menu = menu[\n",
        "    (menu[\"restaurant_id\"] == cold_rid)\n",
        "    & (menu[\"availability\"])\n",
        "    & (menu[\"margin_pct\"] >= 10)\n",
        "]\n",
        "\n",
        "cold_candidates = cgen.generate_candidates(\n",
        "    cart_item_ids=[],\n",
        "    filtered_candidates_df=cold_menu,\n",
        "    restaurant_cuisine=cold_cuisine,\n",
        "    top_k=10,\n",
        ")\n",
        "\n",
        "print(f\"=== Cold Start: Empty Cart at {cold_rid} ({cold_cuisine}) ===\")\n",
        "print(f\"  Available items: {len(cold_menu)}\")\n",
        "print(f\"\\n  Top 10 recommendations:\")\n",
        "for rank, (_, row) in enumerate(cold_candidates.iterrows(), 1):\n",
        "    print(f\"    {rank:>2}. {row['similarity_score']:.4f}  {row['name']:<35} [{row['category']}]\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d972f024"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4b. Veg-Only Session\n",
        "Session with veg toggle — hard filter removes non-veg first, then embeddings rank the remainder."
      ],
      "id": "6ecf5098"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Veg-only session\n",
        "veg_sessions = sessions[sessions[\"dietary_toggle\"] == \"veg\"]\n",
        "vs = veg_sessions.iloc[0]\n",
        "\n",
        "vs_cart = get_cart_items(vs[\"session_id\"])\n",
        "vs_cuisine = get_restaurant_cuisine(vs[\"restaurant_id\"])\n",
        "\n",
        "vs_filtered, vs_flog = pipe.run_filters(\n",
        "    restaurant_id=vs[\"restaurant_id\"],\n",
        "    user_id=vs[\"user_id\"],\n",
        "    session_start=vs[\"start_time\"],\n",
        "    dietary_toggle=\"veg\",\n",
        "    cart_item_ids=vs_cart,\n",
        ")\n",
        "\n",
        "vs_candidates = cgen.generate_candidates(\n",
        "    cart_item_ids=vs_cart,\n",
        "    filtered_candidates_df=vs_filtered,\n",
        "    restaurant_cuisine=vs_cuisine,\n",
        "    top_k=20,\n",
        ")\n",
        "\n",
        "print(f\"=== Veg Session {vs['session_id']} ===\")\n",
        "print(f\"  Restaurant: {vs['restaurant_id']} ({vs_cuisine})\")\n",
        "print(f\"  Cart: {list(get_cart_df(vs_cart)['name'].values)}\")\n",
        "print(f\"  Candidates after hard filters: {len(vs_filtered)}\")\n",
        "print(f\"  Non-veg in candidates: {(~vs_filtered['veg_flag']).sum()}  (should be 0)\")\n",
        "print(f\"\\n  Top 10:\")\n",
        "for rank, (_, row) in enumerate(vs_candidates.head(10).iterrows(), 1):\n",
        "    print(f\"    {rank:>2}. {row['similarity_score']:.4f}  {row['name']:<35} [{'V' if row['veg_flag'] else 'NV'}]\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e8d5b8e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4c. Combo/Thali in Cart\n",
        "When a combo is in the cart, hard filters suppress its component subcategories. Embedding search then ranks what remains."
      ],
      "id": "99c06860"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find a session-like scenario with a combo in cart\n",
        "combos = menu[(menu[\"is_combo\"]) & (menu[\"subcategory\"].isin([\"thali\", \"meal_combo\"]))]\n",
        "sample_combo = combos.iloc[0]\n",
        "combo_rid = sample_combo[\"restaurant_id\"]\n",
        "combo_cuisine = get_restaurant_cuisine(combo_rid)\n",
        "\n",
        "# Simulate a cart with just the combo\n",
        "combo_cart = {sample_combo[\"item_id\"]}\n",
        "combo_filtered, combo_flog = pipe.run_filters(\n",
        "    restaurant_id=combo_rid,\n",
        "    user_id=users.iloc[0][\"user_id\"],\n",
        "    session_start=\"2025-12-15T12:30:00\",\n",
        "    dietary_toggle=\"none\",\n",
        "    cart_item_ids=combo_cart,\n",
        ")\n",
        "\n",
        "combo_candidates = cgen.generate_candidates(\n",
        "    cart_item_ids=combo_cart,\n",
        "    filtered_candidates_df=combo_filtered,\n",
        "    restaurant_cuisine=combo_cuisine,\n",
        "    top_k=15,\n",
        ")\n",
        "\n",
        "components = json.loads(sample_combo[\"combo_components\"])\n",
        "print(f\"=== Combo in Cart ===\")\n",
        "print(f\"  Combo: {sample_combo['name']} ({sample_combo['subcategory']})\")\n",
        "print(f\"  Components: {components}\")\n",
        "print(f\"  Suppressed subcats: {combo_flog['log_C'].get('combo_suppressed_subcats', 'none')}\")\n",
        "print(f\"  Candidates after filters: {len(combo_filtered)}\")\n",
        "print(f\"\\n  Top 10 add-on suggestions:\")\n",
        "for rank, (_, row) in enumerate(combo_candidates.head(10).iterrows(), 1):\n",
        "    print(f\"    {rank:>2}. {row['similarity_score']:.4f}  {row['name']:<35} [{row['subcategory']}]\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e4d6aaa6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Batch Analysis — 100 Sessions\n",
        "\n",
        "Run the full Step 2 + Step 3 pipeline on 100 random sessions. Analyze candidate pool sizes, score distributions, and latency."
      ],
      "id": "19256187"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_sessions = sessions.sample(100, random_state=42)\n",
        "\n",
        "batch_records = []\n",
        "for _, s in sample_sessions.iterrows():\n",
        "    cart_ids = get_cart_items(s[\"session_id\"])\n",
        "    cuisine = get_restaurant_cuisine(s[\"restaurant_id\"])\n",
        "\n",
        "    try:\n",
        "        # Step 2\n",
        "        filtered, flog = pipe.run_filters(\n",
        "            restaurant_id=s[\"restaurant_id\"],\n",
        "            user_id=s[\"user_id\"],\n",
        "            session_start=s[\"start_time\"],\n",
        "            dietary_toggle=s[\"dietary_toggle\"],\n",
        "            cart_item_ids=cart_ids,\n",
        "        )\n",
        "\n",
        "        # Step 3 (timed)\n",
        "        t0 = time.perf_counter()\n",
        "        candidates = cgen.generate_candidates(\n",
        "            cart_item_ids=cart_ids,\n",
        "            filtered_candidates_df=filtered,\n",
        "            restaurant_cuisine=cuisine,\n",
        "            top_k=50,\n",
        "        )\n",
        "        step3_ms = (time.perf_counter() - t0) * 1000\n",
        "\n",
        "        batch_records.append({\n",
        "            \"session_id\": s[\"session_id\"],\n",
        "            \"cart_size\": len(cart_ids),\n",
        "            \"after_filters\": len(filtered),\n",
        "            \"after_step3\": len(candidates),\n",
        "            \"top_score\": candidates[\"similarity_score\"].max() if len(candidates) > 0 else 0,\n",
        "            \"median_score\": candidates[\"similarity_score\"].median() if len(candidates) > 0 else 0,\n",
        "            \"min_score\": candidates[\"similarity_score\"].min() if len(candidates) > 0 else 0,\n",
        "            \"step3_ms\": step3_ms,\n",
        "        })\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "batch_df = pd.DataFrame(batch_records)\n",
        "print(f\"Successfully processed {len(batch_df)} / 100 sessions\")\n",
        "print()\n",
        "print(\"=== Candidate Pool Sizes ===\")\n",
        "print(f\"  After hard filters  : {batch_df['after_filters'].mean():.1f} avg  (range: {batch_df['after_filters'].min()}-{batch_df['after_filters'].max()})\")\n",
        "print(f\"  After Step 3 top-50 : {batch_df['after_step3'].mean():.1f} avg  (range: {batch_df['after_step3'].min()}-{batch_df['after_step3'].max()})\")\n",
        "print()\n",
        "print(\"=== Similarity Scores ===\")\n",
        "print(f\"  Top score    : {batch_df['top_score'].mean():.4f} avg  (range: {batch_df['top_score'].min():.4f}-{batch_df['top_score'].max():.4f})\")\n",
        "print(f\"  Median score : {batch_df['median_score'].mean():.4f} avg\")\n",
        "print(f\"  Min score    : {batch_df['min_score'].mean():.4f} avg\")\n",
        "print()\n",
        "print(\"=== Step 3 Latency ===\")\n",
        "print(f\"  Mean   : {batch_df['step3_ms'].mean():.2f} ms\")\n",
        "print(f\"  Median : {batch_df['step3_ms'].median():.2f} ms\")\n",
        "print(f\"  p95    : {batch_df['step3_ms'].quantile(0.95):.2f} ms\")\n",
        "print(f\"  Max    : {batch_df['step3_ms'].max():.2f} ms\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "44ac67fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Visualizations"
      ],
      "id": "48bec932"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Score distribution across all sessions\n",
        "ax = axes[0, 0]\n",
        "ax.hist(batch_df[\"top_score\"], bins=20, alpha=0.7, color=\"#4C72B0\", edgecolor=\"white\", label=\"Top score\")\n",
        "ax.hist(batch_df[\"median_score\"], bins=20, alpha=0.7, color=\"#55A868\", edgecolor=\"white\", label=\"Median score\")\n",
        "ax.set_xlabel(\"Similarity Score\")\n",
        "ax.set_ylabel(\"Sessions\")\n",
        "ax.set_title(\"Score Distribution Across 100 Sessions\")\n",
        "ax.legend()\n",
        "\n",
        "# 2. Candidate pool size: after filters vs after top-50\n",
        "ax = axes[0, 1]\n",
        "ax.scatter(batch_df[\"after_filters\"], batch_df[\"after_step3\"], alpha=0.6, s=30, color=\"#C44E52\")\n",
        "ax.plot([0, batch_df[\"after_filters\"].max()], [0, batch_df[\"after_filters\"].max()],\n",
        "        \"--\", color=\"gray\", alpha=0.5, label=\"y = x (no reduction)\")\n",
        "ax.set_xlabel(\"Candidates After Hard Filters\")\n",
        "ax.set_ylabel(\"Candidates After Step 3 (top-50)\")\n",
        "ax.set_title(\"Pool Size: Hard Filters vs Step 3\")\n",
        "ax.legend()\n",
        "\n",
        "# 3. Step 3 latency distribution\n",
        "ax = axes[1, 0]\n",
        "ax.hist(batch_df[\"step3_ms\"], bins=25, color=\"#8172B2\", edgecolor=\"white\", alpha=0.8)\n",
        "ax.axvline(batch_df[\"step3_ms\"].median(), color=\"#C44E52\", linestyle=\"--\", label=f\"Median: {batch_df['step3_ms'].median():.2f} ms\")\n",
        "ax.axvline(batch_df[\"step3_ms\"].quantile(0.95), color=\"#CCB974\", linestyle=\"--\", label=f\"p95: {batch_df['step3_ms'].quantile(0.95):.2f} ms\")\n",
        "ax.set_xlabel(\"Latency (ms)\")\n",
        "ax.set_ylabel(\"Sessions\")\n",
        "ax.set_title(\"Step 3 Latency Distribution\")\n",
        "ax.legend()\n",
        "\n",
        "# 4. Extended funnel: Initial -> After Filters -> After Step 3\n",
        "ax = axes[1, 1]\n",
        "# Re-run to get initial counts for the funnel\n",
        "funnel_stages = [\"Initial Menu\", \"After Hard Filters\", \"After Step 3 (top-50)\"]\n",
        "# For initial, we need to count restaurant menu sizes\n",
        "initial_counts = []\n",
        "for _, s in sample_sessions.head(len(batch_df)).iterrows():\n",
        "    rest_menu_size = len(menu[menu[\"restaurant_id\"] == s[\"restaurant_id\"]])\n",
        "    initial_counts.append(rest_menu_size)\n",
        "initial_avg = np.mean(initial_counts)\n",
        "filter_avg = batch_df[\"after_filters\"].mean()\n",
        "step3_avg = batch_df[\"after_step3\"].mean()\n",
        "\n",
        "funnel_vals = [initial_avg, filter_avg, step3_avg]\n",
        "colors = [\"#4C72B0\", \"#55A868\", \"#64B5CD\"]\n",
        "bars = ax.bar(funnel_stages, funnel_vals, color=colors, edgecolor=\"white\", linewidth=0.5)\n",
        "for bar, val in zip(bars, funnel_vals):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.3, f\"{val:.1f}\",\n",
        "            ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
        "ax.set_ylabel(\"Avg Candidates\")\n",
        "ax.set_title(\"Full Funnel: Menu -> Filters -> Step 3\")\n",
        "ax.set_ylim(0, initial_avg * 1.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a6e1a73c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary"
      ],
      "id": "8c992481"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 62)\n",
        "print(\"  STEP 3 — CANDIDATE GENERATION SUMMARY\")\n",
        "print(\"=\" * 62)\n",
        "print()\n",
        "print(f\"  Embedding model  : all-MiniLM-L6-v2\")\n",
        "print(f\"  Embedding dim    : {cgen.dim}\")\n",
        "print(f\"  Items encoded    : {cgen.n_items}\")\n",
        "print(f\"  Storage          : {os.path.getsize(EMBEDDINGS_PATH) / 1024:.0f} KB\")\n",
        "print()\n",
        "print(f\"  Avg filtered pool    : {batch_df['after_filters'].mean():.0f} items\")\n",
        "print(f\"  Avg Step 3 output    : {batch_df['after_step3'].mean():.0f} items (top-50)\")\n",
        "print(f\"  Avg top sim score    : {batch_df['top_score'].mean():.4f}\")\n",
        "print(f\"  Avg median sim score : {batch_df['median_score'].mean():.4f}\")\n",
        "print()\n",
        "print(f\"  Step 3 latency (p50) : {batch_df['step3_ms'].median():.2f} ms\")\n",
        "print(f\"  Step 3 latency (p95) : {batch_df['step3_ms'].quantile(0.95):.2f} ms\")\n",
        "print(f\"  Well within < 1ms budget for dot product at this scale\")\n",
        "print()\n",
        "print(\"  Ready for Step 4 (Feature Assembly)\")\n",
        "print(\"=\" * 62)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "661dcc64"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}